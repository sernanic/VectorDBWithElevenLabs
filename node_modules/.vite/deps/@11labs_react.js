import {
  require_react
} from "./chunk-3TFVT2CW.js";
import {
  __toESM
} from "./chunk-4MBMRILA.js";

// node_modules/@11labs/react/dist/lib.modern.js
var import_react = __toESM(require_react());

// node_modules/@11labs/client/dist/lib.modern.js
function t() {
  return t = Object.assign ? Object.assign.bind() : function(t3) {
    for (var e3 = 1; e3 < arguments.length; e3++) {
      var n3 = arguments[e3];
      for (var s2 in n3) ({}).hasOwnProperty.call(n3, s2) && (t3[s2] = n3[s2]);
    }
    return t3;
  }, t.apply(null, arguments);
}
function e(t3) {
  const e3 = new Uint8Array(t3);
  return window.btoa(String.fromCharCode(...e3));
}
function n(t3) {
  const e3 = window.atob(t3), n3 = e3.length, s2 = new Uint8Array(n3);
  for (let t4 = 0; t4 < n3; t4++) s2[t4] = e3.charCodeAt(t4);
  return s2.buffer;
}
var s = new Blob([`
      const TARGET_SAMPLE_RATE = 16000;
      class RawAudioProcessor extends AudioWorkletProcessor {
        constructor() {
          super();
          this.buffer = []; // Initialize an empty buffer
          this.bufferSize = TARGET_SAMPLE_RATE / 4; // Define the threshold for buffer size to be ~0.25s

          if (globalThis.LibSampleRate && sampleRate !== TARGET_SAMPLE_RATE) {
            globalThis.LibSampleRate.create(1, sampleRate, TARGET_SAMPLE_RATE).then(resampler => {
              this.resampler = resampler;
            });
          }
        }
        process(inputs, outputs) {
          const input = inputs[0]; // Get the first input node
          if (input.length > 0) {
            let channelData = input[0]; // Get the first channel's data

            // Resample the audio if necessary
            if (this.resampler) {
              channelData = this.resampler.full(channelData);
            }

            // Add channel data to the buffer
            this.buffer.push(...channelData);
            // Get max volume 
            let sum = 0.0;
            for (let i = 0; i < channelData.length; i++) {
              sum += channelData[i] * channelData[i];
            }
            const maxVolume = Math.sqrt(sum / channelData.length);
            // Check if buffer size has reached or exceeded the threshold
            if (this.buffer.length >= this.bufferSize) {
              const float32Array = new Float32Array(this.buffer)
              let pcm16Array = new Int16Array(float32Array.length);

              // Iterate through the Float32Array and convert each sample to PCM16
              for (let i = 0; i < float32Array.length; i++) {
                // Clamp the value to the range [-1, 1]
                let sample = Math.max(-1, Math.min(1, float32Array[i]));
            
                // Scale the sample to the range [-32768, 32767] and store it in the Int16Array
                pcm16Array[i] = sample < 0 ? sample * 32768 : sample * 32767;
              }
            
              // Send the buffered data to the main script
              this.port.postMessage([pcm16Array, maxVolume]);
            
              // Clear the buffer after sending
              this.buffer = [];
            }
          }
          return true; // Continue processing
        }
      }
      registerProcessor("raw-audio-processor", RawAudioProcessor);
  `], { type: "application/javascript" });
var o = URL.createObjectURL(s);
var a = class _a {
  static async create(t3) {
    let e3 = null, n3 = null;
    try {
      const s3 = navigator.mediaDevices.getSupportedConstraints().sampleRate;
      e3 = new window.AudioContext(s3 ? { sampleRate: t3 } : {});
      const i3 = e3.createAnalyser();
      s3 || await e3.audioWorklet.addModule("https://cdn.jsdelivr.net/npm/@alexanderolsen/libsamplerate-js@2.1.2/dist/libsamplerate.worklet.js"), await e3.audioWorklet.addModule(o), n3 = await navigator.mediaDevices.getUserMedia({ audio: { sampleRate: { ideal: t3 }, echoCancellation: { ideal: true }, noiseSuppression: { ideal: true } } });
      const r2 = e3.createMediaStreamSource(n3), l3 = new AudioWorkletNode(e3, "raw-audio-processor");
      return r2.connect(i3), i3.connect(l3), new _a(e3, i3, l3, n3);
    } catch (t4) {
      var s2, i2;
      throw null == (s2 = n3) || s2.getTracks().forEach((t5) => t5.stop()), null == (i2 = e3) || i2.close(), t4;
    }
  }
  constructor(t3, e3, n3, s2) {
    this.context = void 0, this.analyser = void 0, this.worklet = void 0, this.inputStream = void 0, this.context = t3, this.analyser = e3, this.worklet = n3, this.inputStream = s2;
  }
  async close() {
    this.inputStream.getTracks().forEach((t3) => t3.stop()), await this.context.close();
  }
};
var i = new Blob(['\n      class AudioConcatProcessor extends AudioWorkletProcessor {\n        constructor() {\n          super();\n          this.buffers = []; // Initialize an empty buffer\n          this.cursor = 0;\n          this.currentBuffer = null;\n          this.wasInterrupted = false;\n          this.finished = false;\n\n          this.port.onmessage = ({ data }) => {\n            switch (data.type) {\n              case "buffer":\n                this.wasInterrupted = false;\n                this.buffers.push(new Int16Array(data.buffer));\n                break;\n              case "interrupt":\n                this.wasInterrupted = true;\n                break;\n              case "clearInterrupted":\n                if (this.wasInterrupted) {\n                  this.wasInterrupted = false;\n                  this.buffers = [];\n                  this.currentBuffer = null;\n                }\n            }\n          };\n        }\n        process(_, outputs) {\n          let finished = false;\n          const output = outputs[0][0];\n          for (let i = 0; i < output.length; i++) {\n            if (!this.currentBuffer) {\n              if (this.buffers.length === 0) {\n                finished = true;\n                break;\n              }\n              this.currentBuffer = this.buffers.shift();\n              this.cursor = 0;\n            }\n\n            output[i] = this.currentBuffer[this.cursor] / 32768;\n            this.cursor++;\n\n            if (this.cursor >= this.currentBuffer.length) {\n              this.currentBuffer = null;\n            }\n          }\n\n          if (this.finished !== finished) {\n            this.finished = finished;\n            this.port.postMessage({ type: "process", finished });\n          }\n\n          return true; // Continue processing\n        }\n      }\n\n      registerProcessor("audio-concat-processor", AudioConcatProcessor);\n    '], { type: "application/javascript" });
var r = URL.createObjectURL(i);
var l = class _l {
  static async create(t3) {
    let e3 = null;
    try {
      e3 = new AudioContext({ sampleRate: t3 });
      const n4 = e3.createAnalyser(), s2 = e3.createGain();
      s2.connect(n4), n4.connect(e3.destination), await e3.audioWorklet.addModule(r);
      const o2 = new AudioWorkletNode(e3, "audio-concat-processor");
      return o2.connect(s2), new _l(e3, n4, s2, o2);
    } catch (t4) {
      var n3;
      throw null == (n3 = e3) || n3.close(), t4;
    }
  }
  constructor(t3, e3, n3, s2) {
    this.context = void 0, this.analyser = void 0, this.gain = void 0, this.worklet = void 0, this.context = t3, this.analyser = e3, this.gain = n3, this.worklet = s2;
  }
  async close() {
    await this.context.close();
  }
};
function c(t3) {
  return !!t3.type;
}
var u = class _u {
  static async create(t3) {
    let e3 = null;
    try {
      var n3;
      const s3 = null != (n3 = t3.origin) ? n3 : "wss://api.elevenlabs.io", o2 = t3.signedUrl ? t3.signedUrl : s3 + "/v1/convai/conversation?agent_id=" + t3.agentId, a2 = ["convai"];
      t3.authorization && a2.push(`bearer.${t3.authorization}`), e3 = new WebSocket(o2, a2);
      const i2 = await new Promise((n4, s4) => {
        e3.addEventListener("open", () => {
          var n5;
          const s5 = { type: "conversation_initiation_client_data" };
          var o3, a3, i3, r3;
          t3.overrides && (s5.conversation_config_override = { agent: { prompt: null == (o3 = t3.overrides.agent) ? void 0 : o3.prompt, first_message: null == (a3 = t3.overrides.agent) ? void 0 : a3.firstMessage, language: null == (i3 = t3.overrides.agent) ? void 0 : i3.language }, tts: { voice_id: null == (r3 = t3.overrides.tts) ? void 0 : r3.voiceId } }), t3.customLlmExtraBody && (s5.custom_llm_extra_body = t3.customLlmExtraBody), null == (n5 = e3) || n5.send(JSON.stringify(s5));
        }, { once: true }), e3.addEventListener("error", s4), e3.addEventListener("close", s4), e3.addEventListener("message", (t4) => {
          const e4 = JSON.parse(t4.data);
          c(e4) && ("conversation_initiation_metadata" === e4.type ? n4(e4.conversation_initiation_metadata_event) : console.warn("First received message is not conversation metadata."));
        }, { once: true });
      }), r2 = i2.conversation_id, l3 = parseInt(i2.agent_output_audio_format.replace("pcm_", ""));
      return new _u(e3, r2, l3);
    } catch (t4) {
      var s2;
      throw null == (s2 = e3) || s2.close(), t4;
    }
  }
  constructor(t3, e3, n3) {
    this.socket = void 0, this.conversationId = void 0, this.sampleRate = void 0, this.socket = t3, this.conversationId = e3, this.sampleRate = n3;
  }
  close() {
    this.socket.close();
  }
  sendMessage(t3) {
    this.socket.send(JSON.stringify(t3));
  }
};
var h = { clientTools: {} };
var d = { onConnect: () => {
}, onDebug: () => {
}, onDisconnect: () => {
}, onError: () => {
}, onMessage: () => {
}, onModeChange: () => {
}, onStatusChange: () => {
} };
var p = class _p {
  static async startSession(e3) {
    const n3 = t({}, h, d, e3);
    n3.onStatusChange({ status: "connecting" });
    let s2 = null, o2 = null, i2 = null;
    try {
      return s2 = await a.create(16e3), o2 = await u.create(e3), i2 = await l.create(o2.sampleRate), new _p(n3, o2, s2, i2);
    } catch (t3) {
      var r2, c2, f;
      throw n3.onStatusChange({ status: "disconnected" }), null == (r2 = o2) || r2.close(), await (null == (c2 = s2) ? void 0 : c2.close()), await (null == (f = i2) ? void 0 : f.close()), t3;
    }
  }
  constructor(t3, s2, o2, a2) {
    var i2 = this;
    this.options = void 0, this.connection = void 0, this.input = void 0, this.output = void 0, this.lastInterruptTimestamp = 0, this.mode = "listening", this.status = "connecting", this.inputFrequencyData = void 0, this.outputFrequencyData = void 0, this.volume = 1, this.endSession = async function() {
      "connected" === i2.status && (i2.updateStatus("disconnecting"), i2.connection.close(), await i2.input.close(), await i2.output.close(), i2.updateStatus("disconnected"));
    }, this.updateMode = (t4) => {
      t4 !== this.mode && (this.mode = t4, this.options.onModeChange({ mode: t4 }));
    }, this.updateStatus = (t4) => {
      t4 !== this.status && (this.status = t4, this.options.onStatusChange({ status: t4 }));
    }, this.onEvent = async function(t4) {
      try {
        const n3 = JSON.parse(t4.data);
        if (!c(n3)) return;
        switch (n3.type) {
          case "interruption":
            n3.interruption_event && (i2.lastInterruptTimestamp = n3.interruption_event.event_id), i2.fadeOutAudio();
            break;
          case "agent_response":
            i2.options.onMessage({ source: "ai", message: n3.agent_response_event.agent_response });
            break;
          case "user_transcript":
            i2.options.onMessage({ source: "user", message: n3.user_transcription_event.user_transcript });
            break;
          case "internal_tentative_agent_response":
            i2.options.onDebug({ type: "tentative_agent_response", response: n3.tentative_agent_response_internal_event.tentative_agent_response });
            break;
          case "client_tool_call":
            if (i2.options.clientTools.hasOwnProperty(n3.client_tool_call.tool_name)) {
              try {
                var e3;
                const t5 = null != (e3 = await i2.options.clientTools[n3.client_tool_call.tool_name](n3.client_tool_call.parameters)) ? e3 : "Client tool execution successful.";
                i2.connection.sendMessage({ type: "client_tool_result", tool_call_id: n3.client_tool_call.tool_call_id, result: t5, is_error: false });
              } catch (t5) {
                i2.onError("Client tool execution failed with following error: " + (null == t5 ? void 0 : t5.message), { clientToolName: n3.client_tool_call.tool_name }), i2.connection.sendMessage({ type: "client_tool_result", tool_call_id: n3.client_tool_call.tool_call_id, result: "Client tool execution failed: " + (null == t5 ? void 0 : t5.message), is_error: true });
              }
              break;
            }
            if (i2.options.onUnhandledClientToolCall) {
              i2.options.onUnhandledClientToolCall(n3.client_tool_call);
              break;
            }
            i2.onError(`Client tool with name ${n3.client_tool_call.tool_name} is not defined on client`, { clientToolName: n3.client_tool_call.tool_name }), i2.connection.sendMessage({ type: "client_tool_result", tool_call_id: n3.client_tool_call.tool_call_id, result: `Client tool with name ${n3.client_tool_call.tool_name} is not defined on client`, is_error: true });
            break;
          case "audio":
            i2.lastInterruptTimestamp <= n3.audio_event.event_id && (i2.addAudioBase64Chunk(n3.audio_event.audio_base_64), i2.updateMode("speaking"));
            break;
          case "ping":
            i2.connection.sendMessage({ type: "pong", event_id: n3.ping_event.event_id });
            break;
          default:
            i2.options.onDebug(n3);
        }
      } catch (e4) {
        return void i2.onError("Failed to parse event data", { event: t4 });
      }
    }, this.onInputWorkletMessage = (t4) => {
      "connected" === this.status && this.connection.sendMessage({ user_audio_chunk: e(t4.data[0].buffer) });
    }, this.onOutputWorkletMessage = ({ data: t4 }) => {
      "process" === t4.type && this.updateMode(t4.finished ? "listening" : "speaking");
    }, this.addAudioBase64Chunk = async function(t4) {
      i2.output.gain.gain.value = i2.volume, i2.output.worklet.port.postMessage({ type: "clearInterrupted" }), i2.output.worklet.port.postMessage({ type: "buffer", buffer: n(t4) });
    }, this.fadeOutAudio = async function() {
      i2.updateMode("listening"), i2.output.worklet.port.postMessage({ type: "interrupt" }), i2.output.gain.gain.exponentialRampToValueAtTime(1e-4, i2.output.context.currentTime + 2), setTimeout(() => {
        i2.output.gain.gain.value = i2.volume, i2.output.worklet.port.postMessage({ type: "clearInterrupted" });
      }, 2e3);
    }, this.onError = (t4, e3) => {
      console.error(t4, e3), this.options.onError(t4, e3);
    }, this.calculateVolume = (t4) => {
      if (0 === t4.length) return 0;
      let e3 = 0;
      for (let n3 = 0; n3 < t4.length; n3++) e3 += t4[n3] / 255;
      return e3 /= t4.length, e3 < 0 ? 0 : e3 > 1 ? 1 : e3;
    }, this.getId = () => this.connection.conversationId, this.setVolume = ({ volume: t4 }) => {
      this.volume = t4;
    }, this.getInputByteFrequencyData = () => (null != this.inputFrequencyData || (this.inputFrequencyData = new Uint8Array(this.input.analyser.frequencyBinCount)), this.input.analyser.getByteFrequencyData(this.inputFrequencyData), this.inputFrequencyData), this.getOutputByteFrequencyData = () => (null != this.outputFrequencyData || (this.outputFrequencyData = new Uint8Array(this.output.analyser.frequencyBinCount)), this.output.analyser.getByteFrequencyData(this.outputFrequencyData), this.outputFrequencyData), this.getInputVolume = () => this.calculateVolume(this.getInputByteFrequencyData()), this.getOutputVolume = () => this.calculateVolume(this.getOutputByteFrequencyData()), this.options = t3, this.connection = s2, this.input = o2, this.output = a2, this.options.onConnect({ conversationId: s2.conversationId }), this.connection.socket.addEventListener("message", (t4) => {
      this.onEvent(t4);
    }), this.connection.socket.addEventListener("error", (t4) => {
      this.updateStatus("disconnected"), this.onError("Socket error", t4);
    }), this.connection.socket.addEventListener("close", () => {
      this.updateStatus("disconnected"), this.options.onDisconnect();
    }), this.input.worklet.port.onmessage = this.onInputWorkletMessage, this.output.worklet.port.onmessage = this.onOutputWorkletMessage, this.updateStatus("connected");
  }
};

// node_modules/@11labs/react/dist/lib.modern.js
function u2() {
  return u2 = Object.assign ? Object.assign.bind() : function(t3) {
    for (var n3 = 1; n3 < arguments.length; n3++) {
      var e3 = arguments[n3];
      for (var r2 in e3) ({}).hasOwnProperty.call(e3, r2) && (t3[r2] = e3[r2]);
    }
    return t3;
  }, u2.apply(null, arguments);
}
function l2(l3) {
  const a2 = (0, import_react.useRef)(null), o2 = (0, import_react.useRef)(null), [c2, s2] = (0, import_react.useState)("disconnected"), [i2, g] = (0, import_react.useState)("listening");
  return (0, import_react.useEffect)(() => () => {
    var t3;
    null == (t3 = a2.current) || t3.endSession();
  }, []), { startSession: async (t3) => {
    if (a2.current) return a2.current.getId();
    if (o2.current) return (await o2.current).getId();
    try {
      return o2.current = p.startSession(u2({}, null != l3 ? l3 : {}, null != t3 ? t3 : {}, { onModeChange: ({ mode: t4 }) => {
        g(t4);
      }, onStatusChange: ({ status: t4 }) => {
        s2(t4);
      } })), a2.current = await o2.current, a2.current.getId();
    } finally {
      o2.current = null;
    }
  }, endSession: async () => {
    const t3 = a2.current;
    a2.current = null, await (null == t3 ? void 0 : t3.endSession());
  }, setVolume: ({ volume: t3 }) => {
    var n3;
    null == (n3 = a2.current) || n3.setVolume({ volume: t3 });
  }, getInputByteFrequencyData: () => {
    var t3;
    return null == (t3 = a2.current) ? void 0 : t3.getInputByteFrequencyData();
  }, getOutputByteFrequencyData: () => {
    var t3;
    return null == (t3 = a2.current) ? void 0 : t3.getOutputByteFrequencyData();
  }, getInputVolume: () => {
    var t3, n3;
    return null != (t3 = null == (n3 = a2.current) ? void 0 : n3.getInputVolume()) ? t3 : 0;
  }, getOutputVolume: () => {
    var t3, n3;
    return null != (t3 = null == (n3 = a2.current) ? void 0 : n3.getOutputVolume()) ? t3 : 0;
  }, status: c2, isSpeaking: "speaking" === i2 };
}
export {
  l2 as useConversation
};
//# sourceMappingURL=@11labs_react.js.map
